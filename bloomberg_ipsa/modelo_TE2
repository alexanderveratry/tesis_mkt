import pandas as pd
import numpy as np

# Cargar datos
data = pd.read_excel('precios_limpios.xlsx')

# Convertir fechas
if 'DATES' in data.columns:
    data['DATES'] = pd.to_datetime(data['DATES'])
    data.set_index('DATES', inplace=True)

# Separar variable dependiente (IPSA Index)
ipsa_column = 'IPSA Index' 


ipsa_prices = data[ipsa_column].copy()


# Variables independientes (todas las demás columnas excepto IPSA)
independent_columns = [col for col in data.columns 
                     if col not in [ipsa_column, 'DATES'] and not col.startswith('Unnamed')]

stock_prices = data[independent_columns].copy()

# Eliminar filas con valores faltantes
stock_prices = stock_prices.dropna()
ipsa_prices = ipsa_prices.loc[stock_prices.index]

# Calcular retornos logarítmicos
stock_returns = np.log(stock_prices / stock_prices.shift(1)).dropna()
ipsa_returns = np.log(ipsa_prices / ipsa_prices.shift(1)).dropna()

# Alinear fechas
common_dates = stock_returns.index.intersection(ipsa_returns.index)
stock_returns = stock_returns.loc[common_dates]
ipsa_returns = ipsa_returns.loc[common_dates]

print(f"Variable dependiente: {ipsa_column if ipsa_column else 'IPSA sintético'}")
print(f"Variables independientes: {len(stock_returns.columns)} activos")
print(f"Período: {stock_returns.index.min()} a {stock_returns.index.max()}")
print(f"Observaciones: {len(stock_returns)}")

def plot_returns(ipsa_returns, stock_returns):
    import matplotlib.pyplot as plt
    
    # Calcular retornos acumulados correctamente
    # Convertir retornos logarítmicos a simples y luego calcular productoria
    ipsa_simple_returns = np.exp(ipsa_returns) - 1
    stock_simple_returns = np.exp(stock_returns) - 1
    
    ipsa_cumulative = (1 + ipsa_simple_returns).cumprod()
    stock_cumulative = (1 + stock_simple_returns).cumprod()
    
    # Encontrar top 5 por retorno acumulado final
    final_returns = stock_cumulative.iloc[-1] - 1
    top5_stocks = final_returns.nlargest(5).index.tolist()
    
    # Graficar
    plt.figure(figsize=(12, 8))
    
    # IPSA
    plt.plot(ipsa_cumulative.index, (ipsa_cumulative - 1) * 100, 
             'red', linewidth=2, label='IPSA Index')
    
    # Top 5 stocks
    colors = ['blue', 'green', 'orange', 'purple', 'brown']
    for i, stock in enumerate(top5_stocks):
        plt.plot(stock_cumulative.index, (stock_cumulative[stock] - 1) * 100,
                color=colors[i], linewidth=1.5, label=stock)
    
    plt.title('Retornos Acumulados: IPSA vs Top 5 Activos (Cálculo Corregido)', fontsize=14, fontweight='bold')
    plt.xlabel('Fecha')
    plt.ylabel('Retorno Acumulado (%)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()
    
    # Mostrar estadísticas
    print(f"\nTop 5 activos por retorno acumulado (cálculo corregido):")
    for i, stock in enumerate(top5_stocks):
        ret = final_returns[stock] * 100
        print(f"{i+1}. {stock}: {ret:.2f}%")
    
    ipsa_final = (ipsa_cumulative.iloc[-1] - 1) * 100
    print(f"\nIPSA Index: {ipsa_final:.2f}%")

# Ejecutar función
#plot_returns(ipsa_returns, stock_returns)

def create_portfolio_and_plot(ipsa_returns, stock_returns):
    import matplotlib.pyplot as plt
    
    # Calcular retornos acumulados correctamente
    # Convertir retornos logarítmicos a simples y luego calcular productoria
    ipsa_simple_returns = np.exp(ipsa_returns) - 1
    stock_simple_returns = np.exp(stock_returns) - 1
    
    ipsa_cumulative = (1 + ipsa_simple_returns).cumprod()
    stock_cumulative = (1 + stock_simple_returns).cumprod()
    
    # Encontrar top 5 por retorno acumulado final
    final_returns = stock_cumulative.iloc[-1] - 1
    top5_stocks = final_returns.nlargest(5).index.tolist()
    
    # Crear pesos del portafolio: 1er lugar 60%, resto 10% cada uno
    portfolio_weights = {}
    portfolio_weights[top5_stocks[0]] = 0.60  # 1er lugar: 60%
    for stock in top5_stocks[1:]:  # Resto: 10% cada uno
        portfolio_weights[stock] = 0.10
    
    # Calcular retornos del portafolio (usando retornos simples)
    portfolio_returns = np.zeros(len(stock_returns))
    for stock, weight in portfolio_weights.items():
        portfolio_returns += stock_simple_returns[stock].values * weight
    
    # Convertir a Series con fechas
    portfolio_returns = pd.Series(portfolio_returns, index=stock_returns.index)
    portfolio_cumulative = (1 + portfolio_returns).cumprod()
    
    # Graficar
    plt.figure(figsize=(14, 10))
    
    # IPSA
    plt.plot(ipsa_cumulative.index, (ipsa_cumulative - 1) * 100, 
             'red', linewidth=3, label='IPSA Index')
    
    # Portafolio
    plt.plot(portfolio_cumulative.index, (portfolio_cumulative - 1) * 100,
             'black', linewidth=3, label='Portafolio (60%-10%-10%-10%-10%)')
    
    # Top 5 stocks individuales
    colors = ['blue', 'green', 'orange', 'purple', 'brown']
    for i, stock in enumerate(top5_stocks):
        plt.plot(stock_cumulative.index, (stock_cumulative[stock] - 1) * 100,
                color=colors[i], linewidth=1.5, alpha=0.7, label=stock)
    
    plt.title('Retornos Acumulados: Portafolio vs Top 5 vs IPSA (Cálculo Corregido)', fontsize=16, fontweight='bold')
    plt.xlabel('Fecha', fontsize=12)
    plt.ylabel('Retorno Acumulado (%)', fontsize=12)
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()
    
    # Mostrar estadísticas
    print(f"\n=== COMPOSICIÓN DEL PORTAFOLIO ===")
    for i, stock in enumerate(top5_stocks):
        weight = portfolio_weights[stock]
        ret = final_returns[stock] * 100
        print(f"{i+1}. {stock}: {weight*100:.0f}% (Retorno: {ret:.2f}%)")
    
    print(f"\n=== RETORNOS FINALES ===")
    portfolio_final = (portfolio_cumulative.iloc[-1] - 1) * 100
    ipsa_final = (ipsa_cumulative.iloc[-1] - 1) * 100
    print(f"Portafolio: {portfolio_final:.2f}%")
    print(f"IPSA Index: {ipsa_final:.2f}%")
    print(f"Excess Return: {portfolio_final - ipsa_final:.2f}%")
    
    return portfolio_weights, portfolio_cumulative

# Ejecutar función del portafolio
#portfolio_weights, portfolio_cumulative = create_portfolio_and_plot(ipsa_returns, stock_returns)

def lasso_tracking_model(ipsa_returns, stock_returns):
    from sklearn.linear_model import Lasso
    from sklearn.preprocessing import StandardScaler
    from scipy.optimize import minimize
    import matplotlib.pyplot as plt
    
    # Usar todas las acciones disponibles
    stock_simple_returns = np.exp(stock_returns) - 1
    stock_cumulative = (1 + stock_simple_returns).cumprod()

    ipsa_simple_returns = np.exp(ipsa_returns) - 1
    ipsa_cumulative = (1 + ipsa_simple_returns).cumprod()
   
    
    # Normalizar datos
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(stock_returns)
    y = ipsa_returns.values
    
    # Función objetivo: minimizar tracking differen
    def objective(weights):
        alpha = 2000
        portfolio_returns = X_scaled @ weights
        tracking_differences = portfolio_returns - y 
        error = np.sum(tracking_differences**2)
        l1_penalty = alpha * np.sum(np.abs(weights))
        return error + l1_penalty  # Suma de cuadrados de diferencias
    
    # Restricción: suma de pesos = 1
    def constraint_sum_weights(weights):
        return weights.sum() - 1.0
    
    # Restricción: pesos entre -1 y 1
    bounds = [(-1, 1) for _ in range(len(stock_returns.columns))]
    
    # Punto inicial: pesos equiponderados
    initial_weights = np.ones(len(stock_returns.columns)) / len(stock_returns.columns)
    
    # Optimización
    constraints = [{'type': 'eq', 'fun': constraint_sum_weights}]
    
    result = minimize(
        objective,
        initial_weights,
        method='SLSQP',
        bounds=bounds,
        constraints=constraints,
        options={'maxiter': 5000}
    )
    
    if result.success:
        lasso_weights = result.x
        print("Optimización LASSO exitosa")
    else:
        print("Optimización falló, usando pesos equiponderados")
        
    
    # Crear diccionario de pesos (todas las acciones)
    lasso_weights_dict = dict(zip(stock_returns.columns, lasso_weights))
    
    # Calcular retornos del portafolio LASSO (usando retornos simples)
    lasso_portfolio_returns = np.zeros(len(stock_returns))
    for stock, weight in lasso_weights_dict.items():
        lasso_portfolio_returns += stock_simple_returns[stock].values * weight
    
    lasso_portfolio_returns = pd.Series(lasso_portfolio_returns, index=stock_returns.index)
    lasso_cumulative = (1 + lasso_portfolio_returns).cumprod()
    
    # Calcular retorno final del IPSA correctamente (una sola vez)
    ipsa_simple_returns = np.exp(ipsa_returns) - 1
    ipsa_cumulative = (1 + ipsa_simple_returns).cumprod()
    final_ipsa_return = (ipsa_cumulative.iloc[-1] - 1) * 100
    
    # Calcular métricas correctamente
    tracking_diff = (lasso_portfolio_returns - ipsa_simple_returns)  # Usar retornos simples, no logarítmicos
    final_lasso_return = (lasso_cumulative.iloc[-1] - 1) * 100
    
    # Graficar
    plt.figure(figsize=(14, 10))
    
    # IPSA (ya calculado arriba)
    plt.plot(ipsa_cumulative.index, (ipsa_cumulative - 1) * 100, 
             'red', linewidth=3, label='IPSA Index')
    
    # Portafolio LASSO
    plt.plot(lasso_cumulative.index, (lasso_cumulative - 1) * 100,
             'black', linewidth=3, label='Portafolio LASSO')
    
    # Top 5 stocks individuales (usando cálculo correcto)
    final_returns = stock_cumulative.iloc[-1] - 1
    top5_stocks = final_returns.nlargest(5).index.tolist()
    
    colors = ['blue', 'green', 'orange', 'purple', 'brown']
    for i, stock in enumerate(top5_stocks):
        plt.plot(stock_cumulative.index, (stock_cumulative[stock] - 1) * 100,
                color=colors[i], linewidth=1.5, alpha=0.7, label=stock)
    
    plt.title('Retornos Acumulados: Portafolio LASSO vs Top 5 vs IPSA (Cálculo Corregido)', fontsize=16, fontweight='bold')
    plt.xlabel('Fecha', fontsize=12)
    plt.ylabel('Retorno Acumulado (%)', fontsize=12)
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()
    
    # NUEVO GRÁFICO: Variación del Portafolio LASSO
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 12))
    
    # Gráfico 1: Tracking Error (Diferencia entre portafolio e IPSA)
    tracking_error = (lasso_cumulative - ipsa_cumulative) * 100
    ax1.plot(tracking_error.index, tracking_error.values, 
             'purple', linewidth=2, label='Tracking Error (Portafolio - IPSA)')
    ax1.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    ax1.set_title('Tracking Error del Portafolio LASSO vs IPSA', fontsize=14, fontweight='bold')
    ax1.set_ylabel('Diferencia de Retorno Acumulado (%)', fontsize=12)
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.tick_params(axis='x', rotation=45)
    
    # Gráfico 2: Rolling Volatility (Volatilidad móvil de 30 días)
    window = 30
    lasso_volatility = lasso_portfolio_returns.rolling(window=window).std() * np.sqrt(252) * 100
    ipsa_volatility = ipsa_simple_returns.rolling(window=window).std() * np.sqrt(252) * 100
    
    ax2.plot(lasso_volatility.index, lasso_volatility.values, 
             'blue', linewidth=2, label=f'Volatilidad Portafolio LASSO ({window}d)')
    ax2.plot(ipsa_volatility.index, ipsa_volatility.values, 
             'red', linewidth=2, label=f'Volatilidad IPSA ({window}d)')
    ax2.set_title('Volatilidad Móvil del Portafolio LASSO vs IPSA', fontsize=14, fontweight='bold')
    ax2.set_xlabel('Fecha', fontsize=12)
    ax2.set_ylabel('Volatilidad Anualizada (%)', fontsize=12)
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    ax2.tick_params(axis='x', rotation=45)
    
    plt.tight_layout()
    plt.show()
    
    # Gráfico adicional: Distribución de Tracking Differences
    plt.figure(figsize=(10, 6))
    plt.hist(tracking_diff.values, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
    plt.axvline(x=tracking_diff.mean(), color='red', linestyle='--', linewidth=2, 
                label=f'Media: {tracking_diff.mean():.4f}')
    plt.axvline(x=tracking_diff.median(), color='green', linestyle='--', linewidth=2, 
                label=f'Mediana: {tracking_diff.median():.4f}')
    plt.title('Distribución de Tracking Differences (Portafolio LASSO - IPSA)', fontsize=14, fontweight='bold')
    plt.xlabel('Tracking Difference', fontsize=12)
    plt.ylabel('Frecuencia', fontsize=12)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()
    
    # NUEVO GRÁFICO: Evolución de la Composición del Portafolio LASSO
    def calculate_rolling_lasso_weights(ipsa_returns, stock_returns, window=252, step=30):
        """
        Calcula pesos LASSO usando ventanas móviles para ver evolución temporal
        """
        weights_evolution = []
        dates = []
        
        # Usar ventanas móviles
        for i in range(window, len(stock_returns), step):
            # Datos de la ventana
            window_ipsa = ipsa_returns.iloc[i-window:i]
            window_stocks = stock_returns.iloc[i-window:i]
            
            # Normalizar datos de la ventana
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(window_stocks)
            y = window_ipsa.values
            
            # Función objetivo para la ventana
            def objective(weights):
                portfolio_returns = X_scaled @ weights
                tracking_differences = portfolio_returns - y 
                return np.sum(tracking_differences**2)
            
            # Restricciones
            def constraint_sum_weights(weights):
                return weights.sum() - 1.0
            
            bounds = [(-1, 1) for _ in range(len(window_stocks.columns))]
            initial_weights = np.ones(len(window_stocks.columns)) / len(window_stocks.columns)
            constraints = [{'type': 'eq', 'fun': constraint_sum_weights}]
            
            # Optimización para esta ventana
            result = minimize(
                objective,
                initial_weights,
                method='SLSQP',
                bounds=bounds,
                constraints=constraints,
                options={'maxiter': 1000}
            )
            
            if result.success:
                weights_evolution.append(result.x)
                dates.append(window_stocks.index[-1])
            else:
                weights_evolution.append(initial_weights)
                dates.append(window_stocks.index[-1])
        
        return pd.DataFrame(weights_evolution, index=dates, columns=stock_returns.columns)
    
    # Calcular evolución de pesos (usando ventana de 1 año, cada mes)
    print("Calculando evolución de composición del portafolio LASSO...")
    weights_evolution = calculate_rolling_lasso_weights(ipsa_returns, stock_returns, window=252, step=30)
    
    # Encontrar las 10 acciones con mayor peso promedio
    avg_weights = weights_evolution.mean()
    top10_stocks = avg_weights.nlargest(10).index.tolist()
    
    # Gráfico de evolución de composición
    plt.figure(figsize=(16, 10))
    
    # Colores para las top 10 acciones
    colors = plt.cm.tab10(np.linspace(0, 1, 10))
    
    # Graficar evolución de pesos para top 10
    for i, stock in enumerate(top10_stocks):
        plt.plot(weights_evolution.index, weights_evolution[stock] * 100, 
                color=colors[i], linewidth=2, label=stock, marker='o', markersize=3)
    
    plt.title('Evolución de la Composición del Portafolio LASSO (Top 10 Acciones)', 
              fontsize=16, fontweight='bold')
    plt.xlabel('Fecha', fontsize=12)
    plt.ylabel('Peso en el Portafolio (%)', fontsize=12)
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()
    
    # Gráfico de heatmap de composición
    plt.figure(figsize=(14, 8))
    
    # Preparar datos para heatmap (solo top 10)
    heatmap_data = weights_evolution[top10_stocks].T * 100
    
    # Crear heatmap
    import seaborn as sns
    sns.heatmap(heatmap_data, 
                cmap='RdYlBu_r', 
                center=0,
                cbar_kws={'label': 'Peso (%)'},
                linewidths=0.5)
    
    plt.title('Heatmap de Composición del Portafolio LASSO (Top 10 Acciones)', 
              fontsize=16, fontweight='bold')
    plt.xlabel('Fecha', fontsize=12)
    plt.ylabel('Acciones', fontsize=12)
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()
    
    # Estadísticas de evolución
    print(f"\n=== EVOLUCIÓN DE COMPOSICIÓN DEL PORTAFOLIO LASSO ===")
    print(f"Período de análisis: {weights_evolution.index[0]} a {weights_evolution.index[-1]}")
    print(f"Número de rebalanceos: {len(weights_evolution)}")
    print(f"Ventana de optimización: 252 días (1 año)")
    print(f"Frecuencia de rebalanceo: 30 días")
    
    print(f"\nTop 10 acciones por peso promedio:")
    for i, stock in enumerate(top10_stocks):
        avg_weight = avg_weights[stock] * 100
        max_weight = weights_evolution[stock].max() * 100
        min_weight = weights_evolution[stock].min() * 100
        std_weight = weights_evolution[stock].std() * 100
        print(f"{i+1:2d}. {stock:15s}: Promedio={avg_weight:6.2f}%, "
              f"Max={max_weight:6.2f}%, Min={min_weight:6.2f}%, Std={std_weight:6.2f}%")
    
    # Calcular estabilidad del portafolio
    portfolio_stability = weights_evolution.std().mean() * 100
    print(f"\nEstabilidad del portafolio (desviación estándar promedio de pesos): {portfolio_stability:.2f}%")
    
    # Mostrar estadísticas
    print(f"\n=== MODELO LASSO - MINIMIZAR TRACKING DIFFERENCES (TODAS LAS ACCIONES) ===")
    print(f"Número total de acciones: {len(stock_returns.columns)}")
    print(f"Tracking Differences - Media: {tracking_diff.mean():.6f}")
    print(f"Tracking Differences - Std: {tracking_diff.std():.6f}")
    print(f"Tracking Differences - Suma cuadrados: {np.sum(tracking_diff**2):.6f}")
    print(f"Retorno final Portafolio LASSO: {final_lasso_return:.2f}%")
    print(f"Retorno final IPSA: {final_ipsa_return:.2f}%")
    print(f"Excess Return: {final_lasso_return - final_ipsa_return:.2f}%")
    
    # Verificación de cálculos
    print(f"\n=== VERIFICACIÓN DE CÁLCULOS ===")
    print(f"IPSA cumulative final: {ipsa_cumulative.iloc[-1]:.6f}")
    print(f"Portafolio LASSO cumulative final: {lasso_cumulative.iloc[-1]:.6f}")
    print(f"IPSA simple returns mean: {ipsa_simple_returns.mean():.6f}")
    print(f"Portafolio LASSO simple returns mean: {lasso_portfolio_returns.mean():.6f}")
    
    # Mostrar pesos de todas las acciones (solo las que tienen peso > 0.001)
    print(f"\n=== PESOS LASSO (TODAS LAS ACCIONES) ===")
    significant_weights = [(stock, weight) for stock, weight in lasso_weights_dict.items() if abs(weight) > 0.001]
    significant_weights.sort(key=lambda x: abs(x[1]), reverse=True)
    
    for i, (stock, weight) in enumerate(significant_weights):
        print(f"{i+1}. {stock}: {weight:.4f}")
    
    print(f"\nTotal de acciones con peso significativo (>0.001): {len(significant_weights)}")
    
    return lasso_weights_dict, lasso_cumulative, weights_evolution

# Ejecutar modelo LASSO
lasso_weights, lasso_cumulative, weights_evolution = lasso_tracking_model(ipsa_returns, stock_returns)
def robust_lasso_tracking_model(ipsa_returns, stock_returns):
    from sklearn.linear_model import Lasso, HuberRegressor
    from sklearn.preprocessing import StandardScaler, RobustScaler
    from sklearn.covariance import LedoitWolf
    from scipy.optimize import minimize
    from scipy.stats import trim_mean
    import matplotlib.pyplot as plt
    import numpy as np
    import pandas as pd
    import seaborn as sns
    
    # Usar todas las acciones disponibles
    stock_simple_returns = np.exp(stock_returns) - 1
    stock_cumulative = (1 + stock_simple_returns).cumprod()

    ipsa_simple_returns = np.exp(ipsa_returns) - 1
    ipsa_cumulative = (1 + ipsa_simple_returns).cumprod()
   
    # ROBUST PREPROCESSING: Usar RobustScaler en lugar de StandardScaler
    # RobustScaler es menos sensible a outliers (usa mediana y MAD)
    scaler = RobustScaler()
    X_scaled = scaler.fit_transform(stock_returns)
    y = ipsa_returns.values
    
    # ROBUST COVARIANCE ESTIMATION: Ledoit-Wolf shrinkage
    # Esto mejora la estimación de la matriz de covarianza
    lw = LedoitWolf()
    robust_cov = lw.fit(stock_returns).covariance_
    
    # WINSORIZATION: Tratamiento de outliers
    def winsorize_returns(returns, limits=(0.05, 0.05)):
        """Aplica winsorización para limitar outliers extremos"""
        from scipy.stats.mstats import winsorize
        winsorized = np.zeros_like(returns)
        for i in range(returns.shape[1]):
            winsorized[:, i] = winsorize(returns[:, i], limits=limits)
        return winsorized
    
    # Aplicar winsorización a los datos escalados
    X_robust = winsorize_returns(X_scaled, limits=(0.05, 0.05))
    
    # FUNCIÓN OBJETIVO ROBUSTA con múltiples penalizaciones
    def robust_objective(weights):
        # Parámetros de penalización
        alpha_l1 = 0.5        # L1 penalty (LASSO)
        alpha_l2 = 0        # L2 penalty (Ridge) para estabilidad
        alpha_weight = 0.3    # Weight concentration penalty
        alpha_turnover = 0.1   # Turnover penalty (si hay pesos previos)
        huber_delta = 0.01     # Parámetro para Huber loss (robustez)
        
        # Retornos del portafolio
        portfolio_returns = X_robust @ weights
        tracking_differences = portfolio_returns - y 
        
        # 1. HUBER LOSS: Más robusto que MSE para outliers
        def huber_loss(residuals, delta=huber_delta):
            abs_residuals = np.abs(residuals)
            quadratic = np.minimum(abs_residuals, delta)
            linear = abs_residuals - quadratic
            return 0.5 * quadratic**2 + delta * linear
        
        # Error principal usando Huber loss
        huber_error = np.sum(huber_loss(tracking_differences))
        
        # 2. L1 PENALTY (LASSO): Para selección de variables
        l1_penalty = alpha_l1 * np.sum(np.abs(weights))
        
        # 3. L2 PENALTY (RIDGE): Para estabilidad
        l2_penalty = alpha_l2 * np.sum(weights**2)
        
        # 4. WEIGHT CONCENTRATION PENALTY: Evita concentración extrema
        # Penaliza portafolios muy concentrados usando entropía
        abs_weights = np.abs(weights)
        normalized_weights = abs_weights / (np.sum(abs_weights) + 1e-8)
        entropy = -np.sum(normalized_weights * np.log(normalized_weights + 1e-8))
        max_entropy = np.log(len(weights))
        concentration_penalty = alpha_weight * (1 - entropy / max_entropy)
        
        # 5. RISK-BASED PENALTY: Usar covarianza robusta
        risk_penalty = 100 * weights.T @ robust_cov @ weights
        
        return huber_error + l1_penalty + l2_penalty + concentration_penalty + risk_penalty
    
    # RESTRICCIONES ROBUSTAS
    def constraint_sum_weights(weights):
        return weights.sum() - 1.0
    
    # Restricción adicional: limitar pesos máximos individuales
    def constraint_max_weight(weights, max_weight=0.15):
        return max_weight - np.max(np.abs(weights))
    
    # Bounds más restrictivos para mayor estabilidad
    max_individual_weight = 0.12  # Máximo 12% en una sola acción
    bounds = [(-max_individual_weight, max_individual_weight) for _ in range(len(stock_returns.columns))]
    
    # INICIALIZACIÓN ROBUSTA: Usar múltiples puntos de inicio
    def get_robust_initial_weights():
        n_stocks = len(stock_returns.columns)
        
        # 1. Pesos equiponderados
        equal_weights = np.ones(n_stocks) / n_stocks
        
        # 2. Pesos basados en correlación inversa con IPSA
        correlations = np.array([stock_returns[stock].corr(ipsa_returns) 
                                for stock in stock_returns.columns])
        inv_corr_weights = (1 - np.abs(correlations))
        inv_corr_weights = inv_corr_weights / inv_corr_weights.sum()
        
        # 3. Pesos basados en volatilidad inversa
        volatilities = stock_returns.std().values
        inv_vol_weights = (1 / volatilities)
        inv_vol_weights = inv_vol_weights / inv_vol_weights.sum()
        
        # 4. Pesos aleatorios con constrainte de suma
        random_weights = np.random.dirichlet(np.ones(n_stocks))
        
        return [equal_weights, inv_corr_weights, inv_vol_weights, random_weights]
    
    # OPTIMIZACIÓN CON MÚLTIPLES INICIALIZACIONES
    initial_weight_sets = get_robust_initial_weights()
    best_result = None
    best_objective = float('inf')
    
    constraints = [
        {'type': 'eq', 'fun': constraint_sum_weights},
        {'type': 'ineq', 'fun': lambda w: constraint_max_weight(w, 0.15)}
    ]
    
    print("Ejecutando optimización robusta con múltiples inicializaciones...")
    
    for i, initial_weights in enumerate(initial_weight_sets):
        try:
            result = minimize(
                robust_objective,
                initial_weights,
                method='SLSQP',
                bounds=bounds,
                constraints=constraints,
                options={'maxiter': 8000, 'ftol': 1e-9}
            )
            
            if result.success and result.fun < best_objective:
                best_result = result
                best_objective = result.fun
                print(f"  Inicialización {i+1}: Exitosa (objetivo={result.fun:.4f})")
            else:
                print(f"  Inicialización {i+1}: {'Exitosa' if result.success else 'Falló'}")
                
        except Exception as e:
            print(f"  Inicialización {i+1}: Error - {str(e)}")
    
    if best_result and best_result.success:
        lasso_weights = best_result.x
        print(f"Optimización robusta exitosa. Mejor objetivo: {best_objective:.4f}")
    else:
        print("Todas las optimizaciones fallaron, usando pesos equiponderados")
        lasso_weights = np.ones(len(stock_returns.columns)) / len(stock_returns.columns)
    
    # Crear diccionario de pesos (todas las acciones)
    lasso_weights_dict = dict(zip(stock_returns.columns, lasso_weights))
    
    # CÁLCULO ROBUSTO DE RETORNOS DEL PORTAFOLIO
    lasso_portfolio_returns = np.zeros(len(stock_returns))
    for stock, weight in lasso_weights_dict.items():
        lasso_portfolio_returns += stock_simple_returns[stock].values * weight
    
    lasso_portfolio_returns = pd.Series(lasso_portfolio_returns, index=stock_returns.index)
    lasso_cumulative = (1 + lasso_portfolio_returns).cumprod()
    
    # Calcular métricas usando estadísticas robustas
    tracking_diff = lasso_portfolio_returns - ipsa_simple_returns
    
    # Usar mediana en lugar de media para estadísticas más robustas
    final_ipsa_return = (ipsa_cumulative.iloc[-1] - 1) * 100
    final_lasso_return = (lasso_cumulative.iloc[-1] - 1) * 100
    
    # MÉTRICAS ROBUSTAS ADICIONALES
    def calculate_robust_metrics(returns1, returns2):
        """Calcula métricas robustas de comparación"""
        diff = returns1 - returns2
        
        metrics = {
            'mean_diff': np.mean(diff),
            'median_diff': np.median(diff),
            'trimmed_mean_diff': trim_mean(diff, 0.1),  # Media recortando 10% extremos
            'mad_diff': np.median(np.abs(diff - np.median(diff))),  # Median Absolute Deviation
            'std_diff': np.std(diff),
            'iqr_diff': np.percentile(diff, 75) - np.percentile(diff, 25),
            'skewness': pd.Series(diff).skew(),
            'kurtosis': pd.Series(diff).kurtosis()
        }
        
        return metrics
    
    robust_metrics = calculate_robust_metrics(lasso_portfolio_returns, ipsa_simple_returns)
    
    # GRÁFICOS MEJORADOS
    plt.figure(figsize=(16, 12))
    
    # Gráfico principal con bandas de confianza
    plt.subplot(2, 2, 1)
    
    # IPSA
    plt.plot(ipsa_cumulative.index, (ipsa_cumulative - 1) * 100, 
             'red', linewidth=3, label='IPSA Index', alpha=0.8)
    
    # Portafolio LASSO robusto
    plt.plot(lasso_cumulative.index, (lasso_cumulative - 1) * 100,
             'black', linewidth=3, label='Portafolio LASSO Robusto')
    
    # Banda de confianza basada en volatilidad rolling
    window = 60
    rolling_vol = lasso_portfolio_returns.rolling(window).std() * np.sqrt(252)
    lasso_return_series = (lasso_cumulative - 1) * 100
    
    upper_band = lasso_return_series + rolling_vol.shift(1) * 100
    lower_band = lasso_return_series - rolling_vol.shift(1) * 100
    
    plt.fill_between(lasso_cumulative.index, upper_band, lower_band, 
                     alpha=0.2, color='gray', label='Banda Confianza (±1σ)')
    
    # Top 3 stocks individuales
    final_returns = stock_cumulative.iloc[-1] - 1
    top3_stocks = final_returns.nlargest(3).index.tolist()
    
    colors = ['blue', 'green', 'orange']
    for i, stock in enumerate(top3_stocks):
        plt.plot(stock_cumulative.index, (stock_cumulative[stock] - 1) * 100,
                color=colors[i], linewidth=1.5, alpha=0.6, label=stock)
    
    plt.title('Retornos Acumulados: Portafolio LASSO Robusto', fontsize=14, fontweight='bold')
    plt.xlabel('Fecha', fontsize=12)
    plt.ylabel('Retorno Acumulado (%)', fontsize=12)
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    
    # Gráfico de tracking error robusto
    plt.subplot(2, 2, 2)
    tracking_error = (lasso_cumulative - ipsa_cumulative) * 100
    
    # Media móvil del tracking error
    tracking_ma = tracking_error.rolling(30).mean()
    
    plt.plot(tracking_error.index, tracking_error.values, 
             'purple', linewidth=1, alpha=0.6, label='Tracking Error')
    plt.plot(tracking_ma.index, tracking_ma.values, 
             'darkblue', linewidth=2, label='Media Móvil (30d)')
    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    
    plt.title('Tracking Error Robusto', fontsize=14, fontweight='bold')
    plt.ylabel('Diferencia (%)', fontsize=12)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    
    # Distribución de tracking differences con estadísticas robustas
    plt.subplot(2, 2, 3)
    plt.hist(tracking_diff.values, bins=40, alpha=0.7, color='lightblue', 
             edgecolor='black', density=True)
    
    # Líneas de estadísticas robustas
    plt.axvline(x=robust_metrics['mean_diff'], color='red', linestyle='-', 
                linewidth=2, label=f'Media: {robust_metrics["mean_diff"]:.4f}')
    plt.axvline(x=robust_metrics['median_diff'], color='green', linestyle='--', 
                linewidth=2, label=f'Mediana: {robust_metrics["median_diff"]:.4f}')
    plt.axvline(x=robust_metrics['trimmed_mean_diff'], color='orange', linestyle=':', 
                linewidth=2, label=f'Media Recortada: {robust_metrics["trimmed_mean_diff"]:.4f}')
    
    plt.title('Distribución Robusta de Tracking Differences', fontsize=14, fontweight='bold')
    plt.xlabel('Tracking Difference', fontsize=12)
    plt.ylabel('Densidad', fontsize=12)
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Métricas de riesgo
    plt.subplot(2, 2, 4)
    
    # VaR y CVaR
    var_95 = np.percentile(tracking_diff, 5) * 100
    cvar_95 = np.mean(tracking_diff[tracking_diff <= np.percentile(tracking_diff, 5)]) * 100
    
    risk_metrics = ['VaR 95%', 'CVaR 95%', 'Volatilidad', 'MAD', 'IQR']
    risk_values = [
        var_95,
        cvar_95,
        robust_metrics['std_diff'] * 100,
        robust_metrics['mad_diff'] * 100,
        robust_metrics['iqr_diff'] * 100
    ]
    
    bars = plt.bar(risk_metrics, risk_values, color=['red', 'darkred', 'blue', 'green', 'orange'],
                   alpha=0.7, edgecolor='black')
    
    plt.title('Métricas de Riesgo Robustas', fontsize=14, fontweight='bold')
    plt.ylabel('Valor (%)', fontsize=12)
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3, axis='y')
    
    # Agregar valores sobre las barras
    for bar, value in zip(bars, risk_values):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                f'{value:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    plt.tight_layout()
    plt.show()
    
    # ANÁLISIS DE COMPOSICIÓN ROBUSTA
    plt.figure(figsize=(14, 8))
    
    # Encontrar acciones con peso significativo
    significant_weights = [(stock, weight) for stock, weight in lasso_weights_dict.items() 
                          if abs(weight) > 0.005]  # Umbral más bajo para capturar más diversificación
    significant_weights.sort(key=lambda x: abs(x[1]), reverse=True)
    
    # Tomar top 15 para visualización
    top_stocks = [x[0] for x in significant_weights[:15]]
    top_weights = [x[1] * 100 for x in significant_weights[:15]]
    
    # Gráfico de barras con colores según peso
    colors = ['darkred' if w < 0 else 'darkgreen' for w in top_weights]
    bars = plt.bar(range(len(top_stocks)), top_weights, color=colors, 
                   alpha=0.7, edgecolor='black')
    
    plt.title('Composición del Portafolio LASSO Robusto (Top 15)', fontsize=16, fontweight='bold')
    plt.xlabel('Acciones', fontsize=12)
    plt.ylabel('Peso (%)', fontsize=12)
    plt.xticks(range(len(top_stocks)), top_stocks, rotation=45, ha='right')
    plt.axhline(y=0, color='black', linestyle='-', alpha=0.5)
    plt.grid(True, alpha=0.3, axis='y')
    
    # Agregar valores sobre las barras
    for i, (bar, value) in enumerate(zip(bars, top_weights)):
        plt.text(bar.get_x() + bar.get_width()/2, 
                bar.get_height() + (0.2 if value > 0 else -0.4),
                f'{value:.1f}%', ha='center', 
                va='bottom' if value > 0 else 'top', 
                fontsize=9, fontweight='bold')
    
    plt.tight_layout()
    plt.show()
    
    # ANÁLISIS DE EVOLUCIÓN TEMPORAL DE LA COMPOSICIÓN
    def calculate_robust_rolling_weights(ipsa_returns, stock_returns, window=252, step=21, min_weight_threshold=0.001):
        """
        Calcula pesos LASSO robustos usando ventanas móviles para ver evolución temporal
        """
        weights_evolution = []
        dates = []
        objectives = []
        
        print(f"Calculando evolución de composición (ventana={window} días, paso={step} días)...")
        
        # Usar ventanas móviles
        total_windows = (len(stock_returns) - window) // step + 1
        
        for i, start_idx in enumerate(range(window, len(stock_returns), step)):
            if start_idx + step > len(stock_returns):
                break
                
            # Mostrar progreso
            if i % 5 == 0:
                progress = (i / total_windows) * 100
                print(f"  Progreso: {progress:.1f}% ({i+1}/{total_windows} ventanas)")
            
            # Datos de la ventana
            end_idx = start_idx
            window_ipsa = ipsa_returns.iloc[start_idx-window:end_idx]
            window_stocks = stock_returns.iloc[start_idx-window:end_idx]
            
            # Preprocessing robusto para la ventana
            scaler = RobustScaler()
            X_scaled = scaler.fit_transform(window_stocks)
            y = window_ipsa.values
            
            # Winsorización
            X_robust = winsorize_returns(X_scaled, limits=(0.05, 0.05))
            
            # Covarianza robusta para la ventana
            lw = LedoitWolf()
            try:
                robust_cov_window = lw.fit(window_stocks).covariance_
            except:
                robust_cov_window = np.eye(len(window_stocks.columns))
            
            # Función objetivo para la ventana (simplificada para velocidad)
            def objective_window(weights):
                alpha_l1 = 0.5
                alpha_l2 = 0
                alpha_weight = 0.1
                huber_delta = 0.01
                
                portfolio_returns = X_robust @ weights
                tracking_differences = portfolio_returns - y 
                
                # Huber loss
                def huber_loss(residuals, delta=huber_delta):
                    abs_residuals = np.abs(residuals)
                    quadratic = np.minimum(abs_residuals, delta)
                    linear = abs_residuals - quadratic
                    return 0.5 * quadratic**2 + delta * linear
                
                huber_error = np.sum(huber_loss(tracking_differences))
                l1_penalty = alpha_l1 * np.sum(np.abs(weights))
                l2_penalty = alpha_l2 * np.sum(weights**2)
                
                # Penalty de concentración
                abs_weights = np.abs(weights)
                normalized_weights = abs_weights / (np.sum(abs_weights) + 1e-8)
                entropy = -np.sum(normalized_weights * np.log(normalized_weights + 1e-8))
                max_entropy = np.log(len(weights))
                concentration_penalty = alpha_weight * (1 - entropy / max_entropy)
                
                # Risk penalty
                risk_penalty = 50 * weights.T @ robust_cov_window @ weights
                
                return huber_error + l1_penalty + l2_penalty + concentration_penalty + risk_penalty
            
            # Restricciones
            def constraint_sum_weights(weights):
                return weights.sum() - 1.0
            
            bounds = [(-0.10, 0.10) for _ in range(len(window_stocks.columns))]
            
            # Inicialización: usar pesos previos si existen, sino equiponderados
            if len(weights_evolution) > 0:
                initial_weights = weights_evolution[-1].copy()
            else:
                initial_weights = np.ones(len(window_stocks.columns)) / len(window_stocks.columns)
            
            constraints = [{'type': 'eq', 'fun': constraint_sum_weights}]
            
            # Optimización para esta ventana
            try:
                result = minimize(
                    objective_window,
                    initial_weights,
                    method='SLSQP',
                    bounds=bounds,
                    constraints=constraints,
                    options={'maxiter': 3000, 'ftol': 1e-6}
                )
                
                if result.success:
                    weights_evolution.append(result.x)
                    objectives.append(result.fun)
                else:
                    weights_evolution.append(initial_weights)
                    objectives.append(np.inf)
                    
            except Exception as e:
                weights_evolution.append(initial_weights)
                objectives.append(np.inf)
            
            dates.append(window_stocks.index[-1])
        
        print("  ✓ Evolución temporal completada")
        return pd.DataFrame(weights_evolution, index=dates, columns=stock_returns.columns), objectives
    
    # Calcular evolución de pesos (usando ventana de 1 año, cada 3 semanas)
    print("\n" + "="*60)
    print("ANÁLISIS DE EVOLUCIÓN TEMPORAL DE LA COMPOSICIÓN")
    print("="*60)
    
    weights_evolution, objectives = calculate_robust_rolling_weights(
        ipsa_returns, stock_returns, window=252, step=21
    )
    
    # GRÁFICO 1: Evolución de los Top Stocks
    plt.figure(figsize=(16, 12))
    
    # Subplot 1: Top 10 stocks por peso promedio
    plt.subplot(2, 2, 1)
    
    avg_weights = weights_evolution.mean()
    top10_stocks = avg_weights.abs().nlargest(10).index.tolist()
    
    colors = plt.cm.Set3(np.linspace(0, 1, 10))
    
    for i, stock in enumerate(top10_stocks):
        plt.plot(weights_evolution.index, weights_evolution[stock] * 100, 
                color=colors[i], linewidth=2.5, label=stock, marker='o', markersize=2, alpha=0.8)
    
    plt.title('Evolución Temporal - Top 10 Acciones por Peso Promedio', 
              fontsize=14, fontweight='bold')
    plt.xlabel('Fecha', fontsize=12)
    plt.ylabel('Peso en el Portafolio (%)', fontsize=12)
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    
    # Subplot 2: Número efectivo de acciones en el tiempo
    plt.subplot(2, 2, 2)
    
    effective_stocks_time = []
    concentration_time = []
    
    for date_idx in range(len(weights_evolution)):
        weights = weights_evolution.iloc[date_idx].values
        abs_weights = np.abs(weights)
        abs_weights = abs_weights / abs_weights.sum()  # Normalizar
        hhi = np.sum(abs_weights**2)
        effective_stocks_time.append(1 / hhi)
        concentration_time.append(hhi)
    
    plt.plot(weights_evolution.index, effective_stocks_time, 
             'darkblue', linewidth=2.5, marker='o', markersize=3, label='Número Efectivo')
    plt.axhline(y=np.mean(effective_stocks_time), color='red', linestyle='--', 
                alpha=0.7, label=f'Promedio: {np.mean(effective_stocks_time):.1f}')
    
    plt.title('Diversificación del Portafolio en el Tiempo', fontsize=14, fontweight='bold')
    plt.xlabel('Fecha', fontsize=12)
    plt.ylabel('Número Efectivo de Acciones', fontsize=12)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    
    # Subplot 3: Concentración (HHI) en el tiempo
    plt.subplot(2, 2, 3)
    
    plt.plot(weights_evolution.index, concentration_time, 
             'darkred', linewidth=2.5, marker='s', markersize=3, label='HHI')
    plt.axhline(y=np.mean(concentration_time), color='blue', linestyle='--', 
                alpha=0.7, label=f'Promedio: {np.mean(concentration_time):.3f}')
    
    plt.title('Índice de Concentración (HHI) en el Tiempo', fontsize=14, fontweight='bold')
    plt.xlabel('Fecha', fontsize=12)
    plt.ylabel('HHI', fontsize=12)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    
    # Subplot 4: Turnover del portafolio
    plt.subplot(2, 2, 4)
    
    turnover_rates = []
    for i in range(1, len(weights_evolution)):
        current_weights = weights_evolution.iloc[i].values
        previous_weights = weights_evolution.iloc[i-1].values
        turnover = np.sum(np.abs(current_weights - previous_weights)) / 2
        turnover_rates.append(turnover)
    
    turnover_dates = weights_evolution.index[1:]
    plt.plot(turnover_dates, np.array(turnover_rates) * 100, 
             'green', linewidth=2.5, marker='^', markersize=3, alpha=0.8)
    plt.axhline(y=np.mean(turnover_rates) * 100, color='orange', linestyle='--', 
                alpha=0.7, label=f'Turnover Promedio: {np.mean(turnover_rates)*100:.2f}%')
    
    plt.title('Turnover del Portafolio en el Tiempo', fontsize=14, fontweight='bold')
    plt.xlabel('Fecha', fontsize=12)
    plt.ylabel('Turnover (%)', fontsize=12)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    
    plt.tight_layout()
    plt.show()
    
    # GRÁFICO 2: Heatmap de evolución temporal
    plt.figure(figsize=(16, 10))
    
    # Preparar datos para heatmap (top 15 acciones)
    top15_stocks = avg_weights.abs().nlargest(15).index.tolist()
    heatmap_data = weights_evolution[top15_stocks].T * 100
    
    # Crear heatmap con mejor resolución
    sns.heatmap(heatmap_data, 
                cmap='RdBu_r', 
                center=0,
                cbar_kws={'label': 'Peso (%)'},
                linewidths=0.1,
                xticklabels=10,  # Mostrar cada 10ma fecha
                yticklabels=True)
    
    plt.title('Heatmap: Evolución Temporal de la Composición (Top 15 Acciones)', 
              fontsize=16, fontweight='bold')
    plt.xlabel('Período de Tiempo', fontsize=12)
    plt.ylabel('Acciones', fontsize=12)
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()
    
    # GRÁFICO 3: Análisis de estabilidad de pesos por acción
    plt.figure(figsize=(14, 8))
    
    # Calcular volatilidad de pesos para cada acción
    weight_volatilities = weights_evolution.std() * 100
    weight_means = weights_evolution.mean() * 100
    
    # Scatter plot: peso promedio vs volatilidad del peso
    significant_stocks = avg_weights.abs().nlargest(20).index
    
    x_vals = [weight_means[stock] for stock in significant_stocks]
    y_vals = [weight_volatilities[stock] for stock in significant_stocks]
    
    plt.scatter(x_vals, y_vals, s=100, alpha=0.7, c='darkblue', edgecolors='black')
    
    # Agregar etiquetas para acciones importantes
    for i, stock in enumerate(significant_stocks[:10]):  # Solo top 10 para claridad
        plt.annotate(stock, (x_vals[i], y_vals[i]), 
                    xytext=(5, 5), textcoords='offset points',
                    fontsize=9, alpha=0.8)
    
    plt.axhline(y=np.median(y_vals), color='red', linestyle='--', alpha=0.7,
                label=f'Volatilidad Mediana: {np.median(y_vals):.2f}%')
    plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)
    
    plt.title('Estabilidad de Pesos: Peso Promedio vs Volatilidad del Peso', 
              fontsize=14, fontweight='bold')
    plt.xlabel('Peso Promedio (%)', fontsize=12)
    plt.ylabel('Volatilidad del Peso (%)', fontsize=12)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()
    
    # GRÁFICO 4: Timeline de cambios significativos
    plt.figure(figsize=(16, 8))
    
    # Detectar cambios significativos en composición
    significant_changes = []
    change_threshold = 0.02  # 2% de cambio en peso
    
    for i in range(1, len(weights_evolution)):
        current_weights = weights_evolution.iloc[i]
        previous_weights = weights_evolution.iloc[i-1]
        
        # Encontrar cambios significativos
        weight_changes = current_weights - previous_weights
        large_changes = weight_changes[abs(weight_changes) > change_threshold]
        
        if len(large_changes) > 0:
            date = weights_evolution.index[i]
            significant_changes.append({
                'date': date,
                'changes': large_changes.to_dict(),
                'total_change': abs(weight_changes).sum()
            })
    
    # Visualizar timeline de cambios
    if significant_changes:
        dates = [change['date'] for change in significant_changes]
        total_changes = [change['total_change'] for change in significant_changes]
        
        plt.subplot(2, 1, 1)
        plt.plot(weights_evolution.index, [0]*len(weights_evolution), 'k-', alpha=0.3)
        plt.scatter(dates, [1]*len(dates), s=[tc*5000 for tc in total_changes], 
                   c='red', alpha=0.6, edgecolors='black')
        
        plt.title('Timeline de Cambios Significativos en Composición', 
                  fontsize=14, fontweight='bold')
        plt.ylabel('Eventos de\nRebalanceo', fontsize=12)
        plt.xticks(rotation=45)
        plt.grid(True, alpha=0.3)
        
        # Mostrar detalles de los 5 mayores cambios
        plt.subplot(2, 1, 2)
        top_changes = sorted(significant_changes, key=lambda x: x['total_change'], reverse=True)[:5]
        
        change_details = []
        change_labels = []
        
        for i, change in enumerate(top_changes):
            date_str = change['date'].strftime('%Y-%m-%d')
            change_labels.append(date_str)
            change_details.append(change['total_change'])
        
        bars = plt.bar(range(len(change_details)), change_details, 
                      color='darkred', alpha=0.7, edgecolor='black')
        
        plt.title('Top 5 Eventos de Mayor Rebalanceo', fontsize=14, fontweight='bold')
        plt.xlabel('Fecha del Evento', fontsize=12)
        plt.ylabel('Magnitud Total del Cambio', fontsize=12)
        plt.xticks(range(len(change_labels)), change_labels, rotation=45)
        plt.grid(True, alpha=0.3, axis='y')
        
        # Agregar valores sobre las barras
        for bar, value in zip(bars, change_details):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                    f'{value:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    plt.tight_layout()
    plt.show()
    
    # ESTADÍSTICAS DE EVOLUCIÓN TEMPORAL
    print(f"\n=== ESTADÍSTICAS DE EVOLUCIÓN TEMPORAL ===")
    print(f"Período de análisis: {weights_evolution.index[0]} a {weights_evolution.index[-1]}")
    print(f"Número de rebalanceos: {len(weights_evolution)}")
    print(f"Frecuencia de rebalanceo: 21 días (~3 semanas)")
    print(f"Ventana de optimización: 252 días (1 año)")
    
    print(f"\n=== MÉTRICAS DE DIVERSIFICACIÓN ===")
    print(f"Número efectivo de acciones:")
    print(f"  Promedio: {np.mean(effective_stocks_time):.1f}")
    print(f"  Mínimo: {np.min(effective_stocks_time):.1f}")
    print(f"  Máximo: {np.max(effective_stocks_time):.1f}")
    print(f"  Desviación estándar: {np.std(effective_stocks_time):.1f}")
    
    print(f"\nÍndice de Concentración (HHI):")
    print(f"  Promedio: {np.mean(concentration_time):.3f}")
    print(f"  Mínimo: {np.min(concentration_time):.3f}")
    print(f"  Máximo: {np.max(concentration_time):.3f}")
    
    print(f"\n=== MÉTRICAS DE ESTABILIDAD ===")
    print(f"Turnover promedio: {np.mean(turnover_rates)*100:.2f}% por rebalanceo")
    print(f"Turnover anualizado: {np.mean(turnover_rates)*100*(252/21):.1f}%")
    print(f"Número de cambios significativos (>2%): {len(significant_changes)}")
    
    # Top 10 acciones más estables (menor volatilidad de peso)
    most_stable = weight_volatilities.nsmallest(10)
    print(f"\n=== TOP 10 ACCIONES MÁS ESTABLES ===")
    for i, (stock, vol) in enumerate(most_stable.items()):
        avg_weight = weight_means[stock]
        print(f"{i+1:2d}. {stock:15s}: Vol={vol:5.2f}%, Peso Prom={avg_weight:6.2f}%")
    
    # Top 10 acciones con mayor peso promedio en el tiempo
    top_avg_weights = avg_weights.abs().nlargest(10)
    print(f"\n=== TOP 10 ACCIONES POR PESO PROMEDIO TEMPORAL ===")
    for i, (stock, weight) in enumerate(top_avg_weights.items()):
        vol = weight_volatilities[stock]
        print(f"{i+1:2d}. {stock:15s}: Peso Prom={weight*100:6.2f}%, Vol={vol:5.2f}%")
    
    # ESTADÍSTICAS FINALES ROBUSTAS
    print(f"\n=== MODELO LASSO ROBUSTO CON PENALIZACIONES ===")
    print(f"Número total de acciones: {len(stock_returns.columns)}")
    print(f"Acciones con peso significativo (>0.5%): {len(significant_weights)}")
    
    print(f"\n=== ESTADÍSTICAS ROBUSTAS DE TRACKING ===")
    for metric, value in robust_metrics.items():
        print(f"{metric.replace('_', ' ').title()}: {value:.6f}")
    
    print(f"\n=== RETORNOS Y PERFORMANCE ===")
    print(f"Retorno final Portafolio LASSO: {final_lasso_return:.2f}%")
    print(f"Retorno final IPSA: {final_ipsa_return:.2f}%")
    print(f"Excess Return: {final_lasso_return - final_ipsa_return:.2f}%")
    
    # Ratio de Sharpe robusto (usando mediana)
    portfolio_sharpe = robust_metrics['trimmed_mean_diff'] / robust_metrics['std_diff'] * np.sqrt(252)
    print(f"Sharpe Ratio (Trimmed Mean): {portfolio_sharpe:.4f}")
    
    # Information Ratio
    info_ratio = robust_metrics['trimmed_mean_diff'] / robust_metrics['std_diff']
    print(f"Information Ratio: {info_ratio:.4f}")
    
    print(f"\n=== MÉTRICAS DE RIESGO ===")
    print(f"VaR 95%: {var_95:.3f}%")
    print(f"CVaR 95%: {cvar_95:.3f}%")
    print(f"Volatilidad anualizada: {robust_metrics['std_diff'] * np.sqrt(252) * 100:.2f}%")
    
    # Concentración del portafolio
    abs_weights = np.abs(list(lasso_weights_dict.values()))
    hhi = np.sum(abs_weights**2)  # Herfindahl-Hirschman Index
    effective_stocks = 1 / hhi
    print(f"\nÍndice Herfindahl-Hirschman: {hhi:.4f}")
    print(f"Número efectivo de acciones: {effective_stocks:.1f}")
    
    print(f"\n=== COMPOSICIÓN PRINCIPAL ===")
    for i, (stock, weight) in enumerate(significant_weights[:10]):
        print(f"{i+1:2d}. {stock:15s}: {weight*100:6.2f}%")
    
    return lasso_weights_dict, lasso_cumulative, robust_metrics

# Ejemplo de uso:
lasso_weights, lasso_cumulative, metrics = robust_lasso_tracking_model(ipsa_returns, stock_returns)